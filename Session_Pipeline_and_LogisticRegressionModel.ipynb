{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from keys import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from S3 bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(\"msds-630-finalproject\")\n",
    "\n",
    "client = boto3.client(\"s3\", aws_access_key_id=access_key, aws_secret_access_key=secret_key)\n",
    "\n",
    "obj = client.get_object(Bucket=\"msds-630-finalproject\", Key=\"sessions.csv\")\n",
    "sessions = pd.read_csv(obj[\"Body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6239836 entries, 0 to 6239835\n",
      "Data columns (total 22 columns):\n",
      "app_id                        int64\n",
      "session_id                    int64\n",
      "start_timestamp               int64\n",
      "timezone                      object\n",
      "timezone_offset               float64\n",
      "previous_sessions_duration    int64\n",
      "user_created_timestamp        int64\n",
      "is_user_first_session         bool\n",
      "is_session                    bool\n",
      "is_developer                  bool\n",
      "is_wau                        bool\n",
      "is_mau                        bool\n",
      "country                       object\n",
      "region                        object\n",
      "city                          object\n",
      "latitude                      float64\n",
      "longitude                     float64\n",
      "locale                        object\n",
      "os_name                       object\n",
      "session_index                 int64\n",
      "device_id                     object\n",
      "user_id_hash                  object\n",
      "dtypes: bool(5), float64(3), int64(6), object(8)\n",
      "memory usage: 839.1+ MB\n"
     ]
    }
   ],
   "source": [
    "sessions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select wanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_selected = sessions[['user_id_hash','start_timestamp','previous_sessions_duration','country','device_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data based on date to separate training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sessions_selected['start_timestamp'] = pd.to_datetime(sessions_selected['start_timestamp'], unit='ms')\n",
    "\n",
    "dec1_cutoff = datetime(2018, 12, 1, 0, 0, 0)\n",
    "dec14_cutoff = datetime(2018, 12, 14, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6239836 entries, 0 to 6239835\n",
      "Data columns (total 5 columns):\n",
      "user_id_hash                  object\n",
      "start_timestamp               datetime64[ns]\n",
      "previous_sessions_duration    int64\n",
      "country                       object\n",
      "device_id                     object\n",
      "dtypes: datetime64[ns](1), int64(1), object(3)\n",
      "memory usage: 238.0+ MB\n"
     ]
    }
   ],
   "source": [
    "sessions_selected.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = sessions_selected[sessions_selected['start_timestamp'] < dec1_cutoff]\n",
    "df_test = sessions_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sessions count, average session duration, country count, device count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.groupby('user_id_hash').agg({'user_id_hash': 'count', 'previous_sessions_duration': 'mean',\n",
    "                                             'country': 'nunique', 'device_id': 'nunique'})\n",
    "df_train = df_train.rename(index=str, columns={\"user_id_hash\": \"session_count\",\n",
    "                                               \"country\": \"country_count\", \"device_id\": \"device_count\"})\n",
    "df_train['user_id_hash'] = df_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.groupby('user_id_hash').agg({'user_id_hash': 'count', 'previous_sessions_duration': 'mean',\n",
    "                                             'country': 'nunique', 'device_id': 'nunique'})\n",
    "df_test = df_test.rename(index=str, columns={\"user_id_hash\": \"session_count\",\n",
    "                                               \"country\": \"country_count\", \"device_id\": \"device_count\"})\n",
    "df_test['user_id_hash'] = df_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the labels by user_id_hash, that have done in other script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"features_train.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Validation, Testing data have been splited in other script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_id.csv')\n",
    "val = pd.read_csv('val_id.csv')\n",
    "#test = pd.read_csv('test_id.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join all tables based on user_id_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(index=str, columns={'0':'user_id_hash'})\n",
    "val = val.rename(index=str, columns={'0':'user_id_hash'})\n",
    "#test = test.rename(index=str, columns={'0':'user_id_hash'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2963: FutureWarning: 'user_id_hash' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "train = pd.merge(train, labels, on='user_id_hash')\n",
    "train = pd.merge(train, df_train, on='user_id_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2963: FutureWarning: 'user_id_hash' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "val = pd.merge(val, labels, on='user_id_hash')\n",
    "val = pd.merge(val, df_train, on='user_id_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2963: FutureWarning: 'user_id_hash' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#test = pd.merge(test, labels, on='user_id_hash')\n",
    "#test = pd.merge(test, df_test, on='user_id_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37172 entries, 0 to 37171\n",
      "Data columns (total 9 columns):\n",
      "user_id_hash                    37172 non-null object\n",
      "user_purchase_binary_7_days     37172 non-null float64\n",
      "user_purchase_binary_14_days    37172 non-null float64\n",
      "num_purchase                    37172 non-null float64\n",
      "value_purchase                  37172 non-null float64\n",
      "session_count                   37172 non-null int64\n",
      "previous_sessions_duration      37172 non-null float64\n",
      "country_count                   37172 non-null int64\n",
      "device_count                    37172 non-null int64\n",
      "dtypes: float64(5), int64(3), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "val.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our first model is using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[['session_count','previous_sessions_duration','country_count','device_count']]\n",
    "train_y7 = train['user_purchase_binary_7_days']\n",
    "train_y14 = train['user_purchase_binary_14_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = val[['session_count','previous_sessions_duration','country_count','device_count']]\n",
    "val_y7 = val['user_purchase_binary_7_days']\n",
    "val_y14 = val['user_purchase_binary_14_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = df_test[['session_count','previous_sessions_duration','country_count','device_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_week = LogisticRegression()\n",
    "log_model_week.fit(train_X, train_y7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9898478174611127"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(log_model_week.predict(train_X),train_y7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9318573119552351"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(log_model_week.predict(val_X),val_y7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_pred1week = log_model_week.predict_proba(test_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_2week = LogisticRegression()\n",
    "log_model_2week.fit(train_X, train_y14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866895388031407"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(log_model_2week.predict(train_X),train_y14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111965995910901"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(log_model_2week.predict(val_X),val_y14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_pred2week = log_model_2week.predict_proba(test_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_model1 = pd.DataFrame({'user_id_hash': df_test['user_id_hash'],'user_purchase_binary_7_days': model1_pred1week,\n",
    "                              'user_purchase_binary_14_days': model1_pred2week})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_model1 = result_model1.sort_values(by=['user_purchase_binary_7_days', 'user_purchase_binary_14_days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621106"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_model1.to_csv('result_model1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
