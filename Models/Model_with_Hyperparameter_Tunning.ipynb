{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:30:47.480824Z",
     "start_time": "2019-03-05T06:30:47.477427Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:21:10.088466Z",
     "start_time": "2019-03-05T06:21:06.853658Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_train = pd.read_csv(\"feature_train.csv\")\n",
    "feature_test = pd.read_csv(\"feature_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:21:11.633768Z",
     "start_time": "2019-03-05T06:21:10.642027Z"
    }
   },
   "outputs": [],
   "source": [
    "res = pd.read_csv('sample_submission_2.csv')\n",
    "feature_test = pd.merge(res, feature_test, on='user_id_hash', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:21:12.224714Z",
     "start_time": "2019-03-05T06:21:12.167369Z"
    }
   },
   "outputs": [],
   "source": [
    "# load training data\n",
    "X_train_7 = feature_train[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66']]\n",
    "y_train_7 = feature_train['user_purchase_binary_7_days']\n",
    "\n",
    "X_train_14 = feature_train[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66']]\n",
    "y_train_14 = feature_train['user_purchase_binary_14_days']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:10:06.529977Z",
     "start_time": "2019-03-05T06:10:06.404656Z"
    }
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_7, y_train_7, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:10:08.258685Z",
     "start_time": "2019-03-05T06:10:08.141517Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_7 = RandomForestClassifier(n_estimators=1000, max_depth=20,criterion='entropy',oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:18:22.285682Z",
     "start_time": "2019-03-05T06:10:09.197834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit random forest model\n",
    "rf_7.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:20:10.504909Z",
     "start_time": "2019-03-05T06:20:00.456214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9860080594014213"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get validation AUC score \n",
    "y_hat = rf_7.predict_proba(X_val)\n",
    "y_pred = pd.DataFrame(y_hat)[1]\n",
    "roc_auc_score(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T06:07:27.860837Z",
     "start_time": "2019-03-03T05:58:49.582036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9843854784338717"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation score for purchasing in 14 days\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_14, y_train_14, test_size=0.2)\n",
    "rf_14 = RandomForestClassifier(n_estimators=1000, max_depth=20,criterion='entropy',oob_score=True)\n",
    "rf_14.fit(X_train,y_train)\n",
    "y_hat = rf_14.predict_proba(X_val)\n",
    "y_pred = pd.DataFrame(y_hat)[1]\n",
    "roc_auc_score(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T06:43:53.045965Z",
     "start_time": "2019-03-03T06:43:52.994130Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_7 = feature_train[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66']]\n",
    "y_train_7 = feature_train['user_purchase_binary_7_days']\n",
    "\n",
    "X_train_14 = feature_train[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66']]\n",
    "y_train_14 = feature_train['user_purchase_binary_14_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T06:36:01.440940Z",
     "start_time": "2019-03-03T06:22:03.633337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=25, min_child_weight=1, missing=None, n_estimators=400,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_7, y_train_7, test_size=0.2)\n",
    "model_7 = xgb.XGBClassifier(n_estimators=400,max_depth=25, learning_rate=0.05)\n",
    "model_7.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T06:36:36.083418Z",
     "start_time": "2019-03-03T06:36:28.206525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9848283012795341"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC score for validation\n",
    "y_hat = model_7.predict_proba(X_val)\n",
    "y_pred = pd.DataFrame(y_hat)[1]\n",
    "roc_auc_score(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:02:35.460608Z",
     "start_time": "2019-03-03T06:48:13.554075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=25, min_child_weight=1, missing=None, n_estimators=400,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_14, y_train_14, test_size=0.2)\n",
    "model_14 = xgb.XGBClassifier(n_estimators=400,max_depth=25,learning_rate=0.05)\n",
    "model_14.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:02:44.405282Z",
     "start_time": "2019-03-03T07:02:35.463824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9846913659820868"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC score for validation\n",
    "y_hat = model_14.predict_proba(X_val)\n",
    "y_pred = pd.DataFrame(y_hat)[1]\n",
    "roc_auc_score(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:16:56.151478Z",
     "start_time": "2019-03-03T07:16:56.117785Z"
    }
   },
   "outputs": [],
   "source": [
    "X_pred = feature_test[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:18:16.222470Z",
     "start_time": "2019-03-03T07:16:57.132152Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_7 = model_7.predict_proba(X_pred)\n",
    "y_pred_7 = pd.DataFrame(y_pred_7)[1]\n",
    "\n",
    "y_pred_14 = model_14.predict_proba(X_pred)\n",
    "y_pred_14 = pd.DataFrame(y_pred_14)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:19:28.430952Z",
     "start_time": "2019-03-03T07:19:28.401373Z"
    }
   },
   "outputs": [],
   "source": [
    "result = result[['user_id_hash','7_days','14_days']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:20:00.022399Z",
     "start_time": "2019-03-03T07:19:59.983438Z"
    }
   },
   "outputs": [],
   "source": [
    "res['user_purchase_binary_7_days'] = pred_7\n",
    "res['user_purchase_binary_14_days'] = pred_14\n",
    "res = res.fillna(0) # new users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:20:36.220174Z",
     "start_time": "2019-03-03T07:20:36.216874Z"
    }
   },
   "outputs": [],
   "source": [
    "res.columns = ['user_id_hash', 'user_purchase_binary_7_days', 'user_purchase_binary_14_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T07:22:35.957775Z",
     "start_time": "2019-03-03T07:22:34.507958Z"
    }
   },
   "outputs": [],
   "source": [
    "res.to_csv('result_gb.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notice that the dataset is unbalanced, we decide to do under sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:21:18.505499Z",
     "start_time": "2019-03-05T06:21:18.137637Z"
    }
   },
   "outputs": [],
   "source": [
    "# under sampling to get balanced data\n",
    "df_train, df_val = train_test_split(feature_train, test_size=0.2)\n",
    "no_purchase = len(df_train[df_train['user_purchase_binary_7_days'] == 1])\n",
    "non_purchase_indices = df_train[df_train['user_purchase_binary_7_days'] == 0].index\n",
    "random_indices = np.random.choice(non_purchase_indices, no_purchase, replace=False)\n",
    "purchase_indices = df_train[df_train['user_purchase_binary_7_days'] == 1].index\n",
    "under_sample_indices = np.concatenate([purchase_indices,random_indices])\n",
    "under_sample = df_train.loc[under_sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>user_purchase_binary_7_days</th>\n",
       "      <th>user_purchase_binary_14_days</th>\n",
       "      <th>unique_session</th>\n",
       "      <th>purchase_before</th>\n",
       "      <th>value_purchase</th>\n",
       "      <th>sessions_duration</th>\n",
       "      <th>os_freq</th>\n",
       "      <th>pct_country</th>\n",
       "      <th>pct_city</th>\n",
       "      <th>0</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76112</th>\n",
       "      <td>c77cb6840dc194463c2cd31446c2afd6898b6394d46896...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676836</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56572</th>\n",
       "      <td>70f92c8fa7e57977200b94723afb03057feb235512574c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.672000</td>\n",
       "      <td>0.047972</td>\n",
       "      <td>0.676836</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137969</th>\n",
       "      <td>b1dc3dd93616585476a047c86610131af1edee22772891...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.676836</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27842</th>\n",
       "      <td>5e4a5038d943864a0afd8f6fe3a4b4911277b70b069143...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>43.336999</td>\n",
       "      <td>0.068701</td>\n",
       "      <td>0.676836</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>7ab6d7a12a41aa35981369dafd3fba4d4fbc2ffaac6fae...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.065000</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.311655</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             user_id_hash  \\\n",
       "76112   c77cb6840dc194463c2cd31446c2afd6898b6394d46896...   \n",
       "56572   70f92c8fa7e57977200b94723afb03057feb235512574c...   \n",
       "137969  b1dc3dd93616585476a047c86610131af1edee22772891...   \n",
       "27842   5e4a5038d943864a0afd8f6fe3a4b4911277b70b069143...   \n",
       "1380    7ab6d7a12a41aa35981369dafd3fba4d4fbc2ffaac6fae...   \n",
       "\n",
       "        user_purchase_binary_7_days  user_purchase_binary_14_days  \\\n",
       "76112                           1.0                           1.0   \n",
       "56572                           1.0                           1.0   \n",
       "137969                          1.0                           1.0   \n",
       "27842                           1.0                           1.0   \n",
       "1380                            1.0                           1.0   \n",
       "\n",
       "        unique_session  purchase_before  value_purchase  sessions_duration  \\\n",
       "76112              1.0              0.0        0.000000           0.000000   \n",
       "56572             41.0              4.0        7.672000           0.047972   \n",
       "137969             5.0              0.0        0.000000           0.004336   \n",
       "27842             37.0              9.0       43.336999           0.068701   \n",
       "1380               5.0              5.0        9.065000           0.002840   \n",
       "\n",
       "         os_freq  pct_country  pct_city      0   66     67  \n",
       "76112   0.676836     0.004570  0.047619   19.0  0.0    0.0  \n",
       "56572   0.676836     0.003060  0.500000   77.0  0.0   72.0  \n",
       "137969  0.676836     0.004570  0.029197    0.0  0.0    0.0  \n",
       "27842   0.676836     0.003346  0.041667   76.0  0.0    0.0  \n",
       "1380    0.311655     0.004570  0.021333  122.0  0.0  118.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:21:19.738374Z",
     "start_time": "2019-03-05T06:21:19.723973Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_7 = under_sample[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66']]\n",
    "y_train_7 = under_sample['user_purchase_binary_7_days']\n",
    "X_val_7 = df_val[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66']]\n",
    "y_val_7 = df_val['user_purchase_binary_7_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:21:36.027349Z",
     "start_time": "2019-03-05T06:21:21.377419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=20, min_child_weight=1, missing=None, n_estimators=5000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0.005, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_under = xgb.XGBClassifier(n_estimators=5000, max_depth=20, learning_rate=0.01, reg_alpha=0.005)\n",
    "model_7_under.fit(X_train_7,y_train_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:21:48.924793Z",
     "start_time": "2019-03-05T06:21:38.085392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968679047816572"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC for validation\n",
    "y_hat = model_7_under.predict_proba(X_val_7)\n",
    "y_pred = pd.DataFrame(y_hat)[1]\n",
    "roc_auc_score(y_val_7,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:21:52.389331Z",
     "start_time": "2019-03-05T06:21:52.010859Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(feature_train, test_size=0.2)\n",
    "no_purchase = len(df_train[df_train['user_purchase_binary_14_days'] == 1])\n",
    "non_purchase_indices = df_train[df_train['user_purchase_binary_14_days'] == 0].index\n",
    "random_indices = np.random.choice(non_purchase_indices, no_purchase, replace=False)\n",
    "purchase_indices = df_train[df_train['user_purchase_binary_14_days'] == 1].index\n",
    "under_sample_indices = np.concatenate([purchase_indices,random_indices])\n",
    "under_sample = df_train.loc[under_sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:54:55.106121Z",
     "start_time": "2019-03-05T06:54:55.096502Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_14 = under_sample[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66']]\n",
    "y_train_14 = under_sample['user_purchase_binary_14_days']\n",
    "X_val_14 = df_val[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66']]\n",
    "y_val_14 = df_val['user_purchase_binary_14_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:22:12.980742Z",
     "start_time": "2019-03-05T06:21:54.165517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=20, min_child_weight=1, missing=None, n_estimators=5000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0.005, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_14_under = xgb.XGBClassifier(n_estimators=5000, max_depth=20, learning_rate=0.01, reg_alpha=0.005)\n",
    "model_14_under.fit(X_train_14,y_train_14)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:22:24.521528Z",
     "start_time": "2019-03-05T06:22:12.983459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9650458241672074"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Auc for validation\n",
    "y_hat = model_14_under.predict_proba(X_val_14)\n",
    "y_pred = pd.DataFrame(y_hat)[1]\n",
    "roc_auc_score(y_val_14,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T06:49:06.447426Z",
     "start_time": "2019-02-27T06:49:06.421106Z"
    }
   },
   "outputs": [],
   "source": [
    "X_pred = feature_test[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T06:49:37.083875Z",
     "start_time": "2019-02-27T06:49:07.093690Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_7 = model_7_under.predict_proba(X_pred)\n",
    "y_pred_7 = pd.DataFrame(y_pred_7)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T06:51:43.124259Z",
     "start_time": "2019-02-27T06:51:00.816077Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_14 = model_14_under.predict_proba(X_pred)\n",
    "y_pred_14 = pd.DataFrame(y_pred_14)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:39:14.340985Z",
     "start_time": "2019-03-05T06:39:14.283100Z"
    }
   },
   "outputs": [],
   "source": [
    "res['user_purchase_binary_7_days'] = y_pred_7\n",
    "res['user_purchase_binary_14_days'] = y_pred_14\n",
    "res = res.fillna(0) # new users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T06:51:43.145869Z",
     "start_time": "2019-02-27T06:51:01.839Z"
    }
   },
   "outputs": [],
   "source": [
    "res.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:44:31.801799Z",
     "start_time": "2019-03-05T06:44:31.798189Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:19:20.106081Z",
     "start_time": "2019-03-05T07:19:19.697725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict purchase in 7 days\n",
    "df_train, df_val = train_test_split(feature_train, test_size=0.2)\n",
    "no_purchase = len(df_train[df_train['user_purchase_binary_7_days'] == 1])\n",
    "non_purchase_indices = df_train[df_train['user_purchase_binary_7_days'] == 0].index\n",
    "random_indices = np.random.choice(non_purchase_indices, no_purchase, replace=False)\n",
    "purchase_indices = df_train[df_train['user_purchase_binary_7_days'] == 1].index\n",
    "under_sample_indices = np.concatenate([purchase_indices,random_indices])\n",
    "under_sample = df_train.loc[under_sample_indices]\n",
    "\n",
    "X_train_7 = under_sample[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66','67']]\n",
    "y_train_7 = under_sample['user_purchase_binary_7_days']\n",
    "X_val_7 = df_val[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66','67']]\n",
    "y_val_7 = df_val['user_purchase_binary_7_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:19:21.326638Z",
     "start_time": "2019-03-05T07:19:21.320450Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train_7)\n",
    "y_train = np.array(y_train_7)\n",
    "X_val = np.array(X_val_7)\n",
    "y_val = np.array(y_val_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:19:22.139384Z",
     "start_time": "2019-03-05T07:19:22.123837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "scaler.fit(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:44:35.033805Z",
     "start_time": "2019-03-05T06:44:35.030753Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:19:26.833196Z",
     "start_time": "2019-03-05T07:19:26.824035Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "feature_train_v = Variable(torch.FloatTensor(X_train), requires_grad = False)\n",
    "labels_train_v = Variable(torch.FloatTensor(y_train), requires_grad = False)\n",
    "feature_test_v = Variable(torch.FloatTensor(X_val), requires_grad = False)\n",
    "labels_test_v = Variable(torch.FloatTensor(y_val), requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:22:25.008907Z",
     "start_time": "2019-03-05T07:22:25.004165Z"
    }
   },
   "outputs": [],
   "source": [
    "# try a simple NN with 2 layers\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self,M=200):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.h_layer_1 = nn.Linear(9, M)\n",
    "        self.h_layer_2 = nn.Linear(M, 1)\n",
    "        self.s_layer_1 = nn.ReLU()\n",
    "        self.s_layer_2 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = self.h_layer_1(x)\n",
    "        y = self.s_layer_1(y)\n",
    "        y = self.h_layer_2(y)\n",
    "        p = self.s_layer_2(y)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:44:53.874449Z",
     "start_time": "2019-03-05T06:44:53.870641Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearClassifier() #declaring the classifier to an object\n",
    "loss_fn = nn.BCELoss() #calculates the loss\n",
    "optim = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:28:38.171845Z",
     "start_time": "2019-03-05T07:22:27.941937Z"
    }
   },
   "outputs": [],
   "source": [
    "all_losses = []\n",
    "for num in range(5000):\n",
    "    pred = model(feature_train_v) \n",
    "    loss = loss_fn(pred, labels_train_v) \n",
    "    all_losses.append(loss.data)\n",
    "    optim.zero_grad() \n",
    "    loss.backward() \n",
    "    optim.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:53:05.810050Z",
     "start_time": "2019-03-05T06:52:55.430068Z"
    }
   },
   "outputs": [],
   "source": [
    "# get predict values\n",
    "predicted_values = []\n",
    "pred = []\n",
    "for num in range(len(feature_test_v)):\n",
    "    predicted_values.append(model(feature_test_v[num]))\n",
    "    pred.append(predicted_values[num].data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:53:06.073126Z",
     "start_time": "2019-03-05T06:53:05.812436Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = np.stack(pred, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:53:06.122910Z",
     "start_time": "2019-03-05T06:53:06.074903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98034204713739"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "roc_auc_score(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:01:42.565289Z",
     "start_time": "2019-03-05T07:01:42.154233Z"
    }
   },
   "outputs": [],
   "source": [
    "#Predict purchase in 14 days\n",
    "df_train, df_val = train_test_split(feature_train, test_size=0.2)\n",
    "no_purchase = len(df_train[df_train['user_purchase_binary_14_days'] == 1])\n",
    "non_purchase_indices = df_train[df_train['user_purchase_binary_14_days'] == 0].index\n",
    "random_indices = np.random.choice(non_purchase_indices, no_purchase, replace=False)\n",
    "purchase_indices = df_train[df_train['user_purchase_binary_14_days'] == 1].index\n",
    "under_sample_indices = np.concatenate([purchase_indices,random_indices])\n",
    "under_sample = df_train.loc[under_sample_indices]\n",
    "\n",
    "X_train_14 = under_sample[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66','67']]\n",
    "y_train_14 = under_sample['user_purchase_binary_14_days']\n",
    "X_val_14 = df_val[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66','67']]\n",
    "y_val_14 = df_val['user_purchase_binary_14_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:01:43.181930Z",
     "start_time": "2019-03-05T07:01:43.175528Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_14 = np.array(X_train_14)\n",
    "y_train_14 = np.array(y_train_14)\n",
    "X_val_14 = np.array(X_val_14)\n",
    "y_val_14 = np.array(y_val_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:01:52.748397Z",
     "start_time": "2019-03-05T07:01:52.727837Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train_14)\n",
    "scaler.fit(X_val_14)\n",
    "\n",
    "feature_train_v_14 = Variable(torch.FloatTensor(X_train_14), requires_grad = False)\n",
    "labels_train_v_14 = Variable(torch.FloatTensor(y_train_14), requires_grad = False)\n",
    "feature_test_v_14 = Variable(torch.FloatTensor(X_val_14), requires_grad = False)\n",
    "labels_test_v_14 = Variable(torch.FloatTensor(y_val_14), requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:02:12.385279Z",
     "start_time": "2019-03-05T07:02:12.381470Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearClassifier() #declaring the classifier to an object\n",
    "loss_fn = nn.BCELoss() #calculates the loss\n",
    "optim = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:03:58.026434Z",
     "start_time": "2019-03-05T07:02:25.865655Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongdouli/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([9836])) that is different to the input size (torch.Size([9836, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    }
   ],
   "source": [
    "all_losses = []\n",
    "for num in range(5000):\n",
    "    pred = model(feature_train_v_14) \n",
    "    loss = loss_fn(pred, labels_train_v_14) \n",
    "    all_losses.append(loss.data)\n",
    "    optim.zero_grad() \n",
    "    loss.backward() \n",
    "    optim.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:05:17.602617Z",
     "start_time": "2019-03-05T07:05:05.172281Z"
    }
   },
   "outputs": [],
   "source": [
    "# get predict values\n",
    "predicted_values = []\n",
    "pred = []\n",
    "for num in range(len(feature_test_v_14)):\n",
    "    predicted_values.append(model(feature_test_v_14[num]))\n",
    "    pred.append(predicted_values[num].data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:05:17.920426Z",
     "start_time": "2019-03-05T07:05:17.605675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9807317077701562"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.stack(pred, axis=1)[0]\n",
    "roc_auc_score(y_val_14,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:28:45.631549Z",
     "start_time": "2019-03-05T07:28:45.624715Z"
    }
   },
   "outputs": [],
   "source": [
    "# add to 3 layers with dropout and lower learning rate\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self,M=300,N=200,p=0.3):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.h_layer_1 = nn.Linear(9, M)\n",
    "        self.h_layer_2 = nn.Linear(M, N)\n",
    "        self.h_layer_3 = nn.Linear(N, 1)\n",
    "        self.s_layer_1 = nn.ReLU()\n",
    "        self.s_layer_2 = nn.ReLU()\n",
    "        self.s_layer_3 = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "    def forward(self,x):\n",
    "        y = self.h_layer_1(x)\n",
    "        y = self.s_layer_1(y)\n",
    "        y = self.h_layer_2(y)\n",
    "        y = self.s_layer_2(y)\n",
    "        y = self.dropout(y)\n",
    "        y = self.h_layer_3(y)\n",
    "        p = self.s_layer_3(y)\n",
    "        return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:35:22.038588Z",
     "start_time": "2019-03-05T07:28:47.944566Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearClassifier() #declaring the classifier to an object\n",
    "loss_fn = nn.BCELoss() #calculates the loss\n",
    "optim = torch.optim.SGD(model.parameters(), lr = 0.05)\n",
    "\n",
    "all_losses = []\n",
    "for num in range(5000):\n",
    "    pred = model(feature_train_v) \n",
    "    loss = loss_fn(pred, labels_train_v) \n",
    "    all_losses.append(loss.data)\n",
    "    optim.zero_grad() \n",
    "    loss.backward() \n",
    "    optim.step() \n",
    "    \n",
    "predicted_values = []\n",
    "pred = []\n",
    "for num in range(len(feature_test_v)):\n",
    "    predicted_values.append(model(feature_test_v[num]))\n",
    "    pred.append(predicted_values[num].data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T07:35:22.377848Z",
     "start_time": "2019-03-05T07:35:22.040588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9836856261984555"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.stack(pred, axis=1)[0]\n",
    "roc_auc_score(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T03:51:29.604024Z",
     "start_time": "2019-03-03T02:24:16.417596Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongdouli/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([9750])) that is different to the input size (torch.Size([9750, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    }
   ],
   "source": [
    "model2 = LinearClassifier() #declaring the classifier to an object\n",
    "loss_fn = nn.BCELoss() #calculates the loss\n",
    "optim = torch.optim.SGD(model2.parameters(), lr = 0.05)\n",
    "\n",
    "all_losses = []\n",
    "for num in range(5000):\n",
    "    pred = model2(feature_train_v_14) \n",
    "    loss = loss_fn(pred, labels_train_v_14) \n",
    "    all_losses.append(loss.data)\n",
    "    optim.zero_grad() \n",
    "    loss.backward() \n",
    "    optim.step() \n",
    "    \n",
    "predicted_values = []\n",
    "pred = []\n",
    "for num in range(len(feature_test_v_14)):\n",
    "    predicted_values.append(model2(feature_test_v_14[num]))\n",
    "    pred.append(predicted_values[num].data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T03:51:29.871758Z",
     "start_time": "2019-03-03T03:51:29.606452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.982436112110718"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.stack(pred, axis=1)[0]\n",
    "roc_auc_score(y_val_14,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T05:19:53.495851Z",
     "start_time": "2019-03-03T05:17:56.482631Z"
    }
   },
   "outputs": [],
   "source": [
    "X_pred = feature_test[['unique_session','purchase_before', 'value_purchase','sessions_duration','pct_country','pct_city','0','66','67']]\n",
    "X_pred = np.array(X_pred)\n",
    "scaler.fit(X_pred)\n",
    "X_pred = Variable(torch.FloatTensor(X_pred), requires_grad = False)\n",
    "predicted_values = []\n",
    "pred_7 = []\n",
    "for num in range(len(X_pred)):\n",
    "    predicted_values.append(model(X_pred[num]))\n",
    "    pred_7.append(predicted_values[num].data.numpy())\n",
    "\n",
    "predicted_values = []\n",
    "pred_14 = []    \n",
    "for num in range(len(X_pred)):\n",
    "    predicted_values.append(model2(X_pred[num]))\n",
    "    pred_14.append(predicted_values[num].data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T05:19:58.020781Z",
     "start_time": "2019-03-03T05:19:56.763568Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_7 = np.stack(pred_7, axis=1)[0]\n",
    "y_pred_14 = np.stack(pred_14, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T05:20:21.867355Z",
     "start_time": "2019-03-03T05:20:21.271869Z"
    }
   },
   "outputs": [],
   "source": [
    "res = pd.read_csv('res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T05:20:44.506143Z",
     "start_time": "2019-03-03T05:20:44.472959Z"
    }
   },
   "outputs": [],
   "source": [
    "res['user_purchase_binary_7_days'] = y_pred_7\n",
    "res['user_purchase_binary_14_days'] = y_pred_14\n",
    "res = res.fillna(0) # new users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-03T05:21:16.063090Z",
     "start_time": "2019-03-03T05:21:14.690127Z"
    }
   },
   "outputs": [],
   "source": [
    "res.to_csv('result_nn.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:22:52.573829Z",
     "start_time": "2019-03-05T06:22:52.569147Z"
    }
   },
   "source": [
    "Gradient boosting gives us the best result, Thus, we do hyper-parameter tunning on Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:23:02.214870Z",
     "start_time": "2019-03-05T06:23:02.201989Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_imp(model):\n",
    "    feat_imp = pd.Series(model.get_booster().get_score(importance_type='weight')).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title = 'Feature Importance')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    \n",
    "def xgbfit(model):  \n",
    "    model.fit(X_train_7, y_train_7, eval_metric='auc')\n",
    "    y_hat_7 = model.predict_proba(X_val_7)\n",
    "    y_pred_7 = pd.DataFrame(y_hat_7)[1]\n",
    "    auc_7 = roc_auc_score(y_val_7, y_pred_7)\n",
    "    print(f\"Val AUC for 7 days: {auc_7}\")\n",
    "    \n",
    "    model.fit(X_train_14, y_train_14, eval_metric='auc')\n",
    "    y_hat_14 = model.predict_proba(X_val_14)\n",
    "    y_pred_14 = pd.DataFrame(y_hat_14)[1]\n",
    "    auc_14 = roc_auc_score(y_val_14, y_pred_14)\n",
    "    print(f\"Val AUC for 14 days: {auc_14}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:23:12.518685Z",
     "start_time": "2019-03-05T06:23:03.695994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC for 7 days: 0.9850454241482748\n",
      "Val AUC for 14 days: 0.9851820988184624\n"
     ]
    }
   ],
   "source": [
    "xgb1 = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=400,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=42)\n",
    "\n",
    "xgbfit(xgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:29:40.866636Z",
     "start_time": "2019-03-05T06:28:36.879593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 15, 'min_child_weight': 1}, 0.9843710400468686)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuning max_depth and child_weight\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "param_test_1 = {\n",
    " 'max_depth': [15,20,22,25,30],\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "\n",
    "gsearch_1 = GridSearchCV(estimator = xgb1, \n",
    "                         param_grid = param_test_1, scoring='roc_auc', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch_1.fit(X_train_7, y_train_7)\n",
    "gsearch_1.best_params_, gsearch_1.best_score_\n",
    "\n",
    "# after done, repeat same but with one below and one above optimum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:24:37.169512Z",
     "start_time": "2019-03-05T06:24:24.099890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_child_weight': 4} 0.9866538236863512\n",
      "CPU times: user 1.38 s, sys: 16 ms, total: 1.4 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_test_2 = {\n",
    " 'max_depth':[3,4],\n",
    " 'min_child_weight':[2,3,4]\n",
    "}\n",
    "gsearch = GridSearchCV(estimator = xgb1, \n",
    "                         param_grid = param_test_2, scoring='roc_auc', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch.fit(X_train_7, y_train_7)\n",
    "print(gsearch.best_params_, gsearch.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:24:52.954792Z",
     "start_time": "2019-03-05T06:24:47.833555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC for 7 days: 0.9859297428622483\n",
      "Val AUC for 14 days: 0.9864148721971132\n"
     ]
    }
   ],
   "source": [
    "# recalibrate the parameters:\n",
    "xgb2 = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=400,\n",
    " max_depth=3,\n",
    " min_child_weight=3,\n",
    " gamma=0.4,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=42)\n",
    "\n",
    "xgbfit(xgb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:25:31.798151Z",
     "start_time": "2019-03-05T06:25:04.092573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6, 'subsample': 0.7} 0.9868046208063405\n"
     ]
    }
   ],
   "source": [
    "# tune subsample and colsample_bytree\n",
    "param_test_4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "\n",
    "gsearch = GridSearchCV(estimator = xgb2, \n",
    "                         param_grid = param_test_4, scoring='roc_auc', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch.fit(X_train_7, y_train_7)\n",
    "print(gsearch.best_params_, gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:25:55.523341Z",
     "start_time": "2019-03-05T06:25:39.726626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.55, 'subsample': 0.7} 0.9868046208063405\n",
      "CPU times: user 1.33 s, sys: 18.4 ms, total: 1.35 s\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#trying values in around 0.7\n",
    "param_test_5 = {\n",
    " 'subsample':[i/100.0 for i in range(65,80,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(55,70,5)]\n",
    "}\n",
    "\n",
    "gsearch = GridSearchCV(estimator = xgb2, \n",
    "                         param_grid = param_test_5, scoring='roc_auc', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch.fit(X_train_7, y_train_7)\n",
    "print(gsearch.best_params_, gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:38:11.154403Z",
     "start_time": "2019-03-05T06:37:58.433350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimator': 400} 0.9864362980277516\n"
     ]
    }
   ],
   "source": [
    "# Tuning n_estimators (num trees)\n",
    "param_test_6 = {\n",
    " 'n_estimator':[400, 500, 600,700, 900]\n",
    "}\n",
    "\n",
    "gsearch = GridSearchCV(estimator = xgb2, \n",
    "                         param_grid = param_test_6, scoring='roc_auc', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch.fit(X_train_7, y_train_7)\n",
    "print(gsearch.best_params_, gsearch.best_score_)\n",
    "#this gives us the best as the lowest, if i drill down until 5 it\n",
    "# still says its the best param, but recalibrating I see the decrease\n",
    "# in AUC, overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:26:11.793508Z",
     "start_time": "2019-03-05T06:26:06.497298Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgbfit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-db0b97156ee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m  seed=42)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mxgbfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xgbfit' is not defined"
     ]
    }
   ],
   "source": [
    "# recalibrating\n",
    "xgb3 = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=19,\n",
    " min_child_weight=3,\n",
    " gamma=0.4,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.55,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=42)\n",
    "\n",
    "xgbfit(xgb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:26:25.586256Z",
     "start_time": "2019-03-05T06:26:16.643485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 0.1} 0.9868471193145428\n"
     ]
    }
   ],
   "source": [
    "# tuning regulatizatiomn\n",
    "param_test_7 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch = GridSearchCV(estimator = xgb3, \n",
    "                         param_grid = param_test_7, scoring='roc_auc', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch.fit(X_train_7, y_train_7)\n",
    "print(gsearch.best_params_, gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:26:34.698560Z",
     "start_time": "2019-03-05T06:26:28.353225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1} 0.9868046208063405\n"
     ]
    }
   ],
   "source": [
    "# lower learning rare\n",
    "param_test_8 = {\n",
    " 'learning_rate':[0.001, 0.01, 0.1]\n",
    "}\n",
    "gsearch = GridSearchCV(estimator = xgb3, \n",
    "                         param_grid = param_test_8, scoring='roc_auc', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch.fit(X_train_7, y_train_7)\n",
    "print(gsearch.best_params_, gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:31:33.924891Z",
     "start_time": "2019-03-05T06:31:33.921279Z"
    }
   },
   "outputs": [],
   "source": [
    "# Final tuned \n",
    "xgb4 = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=19,\n",
    " min_child_weight=3,\n",
    " gamma=0.2,\n",
    "reg_alpha=0.005,\n",
    " subsample=0.8,\n",
    " colsample_bytree=1,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1)\n",
    "\n",
    "\n",
    "\n",
    "#(n_estimators=1000,max_depth=30, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictiction of tuned XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:36:29.544014Z",
     "start_time": "2019-03-05T06:36:29.488727Z"
    }
   },
   "outputs": [],
   "source": [
    "X_pred = feature_test[['unique_session','purchase_before', 'value_purchase','sessions_duration',\n",
    "                       'pct_country','pct_city','0','66']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:36:46.480980Z",
     "start_time": "2019-03-05T06:36:30.484474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC for 7 days: 0.9502327303636142\n"
     ]
    }
   ],
   "source": [
    "xgb4.fit(X_train, y_train, eval_metric='auc')\n",
    "y_hat_7 = xgb4.predict_proba(X_val)\n",
    "y_pred_7 = pd.DataFrame(y_hat_7)[1]\n",
    "auc_7 = roc_auc_score(y_val, y_pred_7)\n",
    "pred_7 = xgb4.predict_proba(X_pred)\n",
    "pred_7 = pd.DataFrame(pred_7)[1]\n",
    "print(f\"Val AUC for 7 days: {auc_7}\")\n",
    "#feature_imp(xgb4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:37:19.160682Z",
     "start_time": "2019-03-05T06:37:01.203775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC for 14 days: 0.9987044682484745\n"
     ]
    }
   ],
   "source": [
    "xgb4.fit(X_train_14, y_train_14, eval_metric='auc')\n",
    "y_hat_14 = xgb4.predict_proba(X_val)\n",
    "y_pred_14 = pd.DataFrame(y_hat_14)[1]\n",
    "auc_14 = roc_auc_score(y_val, y_pred_14)\n",
    "pred_14 = xgb4.predict_proba(X_pred)\n",
    "pred_14 = pd.DataFrame(pred_14)[1]\n",
    "print(f\"Val AUC for 14 days: {auc_14}\")\n",
    "#feature_imp(xgb4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:40:09.363519Z",
     "start_time": "2019-03-05T06:40:09.336822Z"
    }
   },
   "outputs": [],
   "source": [
    "res['user_purchase_binary_7_days'] = pred_7\n",
    "res['user_purchase_binary_14_days'] = pred_14\n",
    "res = res.fillna(0) # new users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T06:40:53.670113Z",
     "start_time": "2019-03-05T06:40:52.293434Z"
    }
   },
   "outputs": [],
   "source": [
    "res.to_csv('result_ht.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
